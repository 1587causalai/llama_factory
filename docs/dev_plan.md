# 开发总纲：我的定制化偏好对齐算法 (dev 分支)

## 1. 背景与反思：为何重新出发？

经过一段时间在偏好对齐领域的探索，尤其回顾我在 `xdpo` 目录下进行的 LeDPO 和 DiscoDPO 相关实验，我深刻感受到之前的实现方式存在一些问题。主要是**逻辑耦合、设计不够清晰、职责分离做得不好**，导致后续迭代和理解都变得困难，有点"历史负担"的感觉。同时，标准的对齐方法（如 DPO）也存在其固有的局限性，比如奖励表示过于简化、策略权衡不够灵活等。

因此，我决定在 LLaMA Factory 这个强大的框架基础上，**彻底重新开始**。我需要一个全新的起点 (`dev` 分支)，来构建一套真正符合我设想的、**逻辑清晰、模块化、灵活且易于测试**的定制化偏好对齐算法。

## 2. 我的核心需求与设计愿景

这次开发的核心目标，不仅仅是复现或改进算法，更是要**深入贯彻我对偏好对齐底层逻辑的理解**。具体来说，包含以下几个关键点：

*   **概率化奖励 (Disco 逻辑)**: 我认为奖励信号天然带有不确定性，需要用概率分布（如高斯）来建模，而不是简单的标量。这就要求相关的模型架构（通过 **Disco Head**）和损失函数（基于分布比较）都要跟上。
*   **自适应权衡 (动态 Beta / LeDPO 逻辑)**: 平衡先验知识和新反馈的 \(\beta\) 参数必须是动态的、上下文相关的。并且，这个决策逻辑应该发生在**参考模型**评估上下文之后，通过在其上添加 **Beta Head** 输出一个作用于**基准 `pref_beta`** 的调节因子来实现。
*   **架构与使用的彻底解耦**: 这次设计的重中之重！必须能分开控制**模型架构中是否有某个 Head** 和**算法运行时是否使用这个 Head 的输出**。这对于模块化开发、调试和严谨的对比实验至关重要。

经过与 AI 助手的反复讨论和迭代，我们共同明确了实现这些理念的**详细参数设计方案**。这份详细的技术蓝图记录在 [`parameter_design.md`](./parameter_design.md) 中（该文档会随着设计的深入而持续更新），它准确地反映了上述需求，并遵循了解耦原则。

同时，我更宏观的开发需求和设计哲学，也沉淀在了 [`../rules/my_preference_alignment_needs.md`](../rules/my_preference_alignment_needs.md) 文档中。

## 3. 接下来的步骤：结构化实现

有了清晰的设计蓝图和明确的需求，接下来的开发工作将遵循**模块化、分阶段**的方式进行。我计划将整个实现过程分解为一系列更小的、功能独立的开发步骤（可能对应不同的特性分支，待后续规划），确保每一步都目标明确、易于验证。

初步设想的开发顺序大致如下（优先级和具体分支待细化）：

1.  **实现基础架构变更**: 
    *   **添加 Disco Head**: 实现 `add_disco_head` 参数功能，让模型具备输出分布参数的能力。
    *   **添加 Beta Head**: 实现 `add_beta_head` 参数功能，在参考模型上添加默认实现的 Beta Head。
2.  **实现核心算法逻辑**: 
    *   **Disco Loss**: 实现 `pref_loss_type: disco` 对应的损失计算逻辑。
    *   **动态 Beta 应用**: 实现 `beta_mode: dynamic_scaling` 对应的、使用 Beta Head 输出调节 `pref_beta` 的逻辑。
3.  **整合与测试**: 将各个模块整合，进行全面的单元测试、集成测试和效果验证实验。
4.  **文档完善**: 随着开发的进行，持续更新相关文档，记录实现细节和遇到的问题。

具体的每一个开发步骤（或特性分支），我都会遵循 [`../rules/doc_style_pref.md`](../rules/doc_style_pref.md) 中定义的偏好，创建详细的说明文档（存放于 `branch_docs/` 目录下），包含目标、实现思路、涉及的参数和必要的背景回顾。

总之，`dev` 分支的目标就是系统性地、高质量地完成上述开发过程，最终得到一套令人满意的、真正体现我设计思想的定制化对齐工具。 