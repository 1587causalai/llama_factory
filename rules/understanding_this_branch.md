# 理解本开发分支 (`dev`) 的个人指南与蓝图

## 背景与目标

这个 `dev` 分支，是我在 LlamaFactory 项目基础上，为了探索和实现一套高度**定制化**的偏好对齐算法而建立的个人开发空间。我的目标是从零开始（或者说，在 LlamaFactory 的基础上），构建一套逻辑清晰、模块化、灵活，并且**深度契合我个人特定需求**的偏好对齐方案。

为了确保这个探索过程有序、思路清晰、知识能够有效沉淀，我设立了几个关键的文档和目录，它们共同构成了这个分支的"蓝图"和"说明书"。本文档就是理解这一切的**入口**，旨在快速引导你（主要是我自己，但也可能是未来的合作者）理解本分支的结构、核心理念和信息分布。

## 关键文档与目录说明

1.  **`rules/understanding_this_branch.md` (本文档)**: **分支指南与蓝图入口**
    *   **内容**: 介绍本 (`dev`) 分支的**背景、目标、整体结构**，以及各个关键文档和目录的职责。特别是解释清楚基于 LlamaFactory 进行二次开发的背景，以及 `custom/` 目录的核心作用。
    *   **作用**: 作为理解本分支**宏观设计和信息分布**的**起点**，帮助按图索骥查找所需信息。

2.  **`docs/dev_plan.md`**: **开发总纲与路线图**
    *   **内容**: 阐述本 (`dev`) 分支的顶层规划，包含更详细的项目背景、核心需求与设计愿景，以及后续结构化的开发步骤计划。
    *   **作用**: 作为进入具体开发工作的**导航页**，指引了解总体方向并找到更详细的技术或需求文档。

3.  **`docs/parameter_design.md`**: **详细技术设计蓝图**
    *   **内容**: 深入阐述为实现我的定制化算法所构思和采用的**具体技术方案**（当前为 V7.3 及后续迭代版本）、参数设计细节、设计理念的逻辑演进过程，并包含一个附录回顾关键决策点。
    *   **作用**: 作为所有具体开发工作必须遵循的**技术规范**和**核心参考**。所有新功能的开发都应以此文档为准。

4.  **`rules/my_preference_alignment_needs.md`**: **高层需求与核心理念**
    *   **内容**: 从我的视角出发，阐述进行本次定制化算法开发的**核心动机**、**关键需求**以及背后坚持的**设计哲学**（例如，我对概率化奖励、自适应权衡、架构解耦等的思考）。
    *   **作用**: 帮助理解本项目**为什么**要这样做，以及最终希望达到的**效果和目标**，是设计的"初心"所在。

5.  **`rules/doc_style_pref.md`**: **文档风格偏好说明**
    *   **内容**: 阐述我对撰写高质量文档（尤其是设计和需求文档）的偏好，强调展现思考过程、逻辑演进，并普遍包含"演进回顾"附录的重要性。
    *   **作用**: 指导本分支及未来相关项目中文档的撰写风格，确保知识的有效沉淀和传递。

6.  **`custom/` 目录**: **实验配置与运行脚本区**
    *   **内容**: 此目录用于存放具体的实验配置文件 (`.yaml`) 和对应的运行脚本 (`.py`)。当前包含一个运行 **DPO 基线实验**的示例：
        *   `dpo_baseline.yaml`: 定义了 DPO 基线实验的模型、数据、超参数等，兼容 LLaMA Factory CLI。
        *   `run_dpo_baseline.py`: 读取 `.yaml` 配置，调用 LLaMA Factory 核心函数来启动和管理 DPO 训练过程。
    *   **作用**: 提供一个独立的区域来组织、配置和启动具体的实验，方便复现和管理不同的实验设置。这与 `src/llamafactory` 目录下进行的核心算法代码修改有所区分。


## 与 LlamaFactory (upstream/main) 的主要差异点

为了让你（或未来的我）快速把握本分支在代码层面的核心定制化工作，这里总结了相对于 LlamaFactory 官方 `main` 分支（假设已添加为 `upstream` 远程仓库）的一些**关键修改和新增之处**。请注意，本分支的开发**仍在进行中**，此列表反映的是**当前阶段**的主要成果，未来会随着开发进展（例如**奖励模型 RM 的相关定制**等）而动态更新。这些改动主要集中在 `src/llamafactory` 目录下，核心目标是引入一套**基于模型隐藏状态动态调整 DPO 算法参数**的机制。

主要差异点按逻辑结构梳理如下：

1.  **新增配置开关 (`hparams/finetuning_args.py`)**:
    *   **内容**: 在 `RLHFArguments` 中添加了 `add_beta_head`, `use_dynamic_beta`, `add_disco_head`, `disco_pref` 等布尔型参数。
    *   **目的**: 提供灵活的开关，用于启用/禁用新的动态参数调整功能及其特定变体（如 Disco-DPO）。

2.  **新增动态参数计算模块 (`train/custom_head.py`)**:
    *   **内容**: 创建了一个全新的文件，定义了 `HiddenStateBetaHead`, `SimpleBetaHead`, `SimpleRewardVarianceHead` 等 `nn.Module` 子类。
    *   **目的**: 这些模块接收模型隐藏状态（通常基于 prompt），通过小型神经网络预测出动态的 DPO `beta` 值或奖励分布方差 (用于 Disco-DPO)。

3.  **深度整合至 DPO 训练器 (`train/dpo/trainer.py`)**:
    *   **初始化与优化器**: 根据配置参数实例化自定义 Head 模块，并将其参数纳入优化器管理。
    *   **前向传播改造**: 修改 `concatenated_forward` 等方法，使其能输出隐藏状态，并调用自定义 Head 计算动态参数 (`beta_values`)。适配了参考模型逻辑 (`ref_model_forward`)。
    *   **损失函数适配**: 重写/修改 `dpo_loss` 及相关函数，使其能使用动态 `beta_values` 替代固定 `beta`。引入了更鲁棒的（对数）偏好概率计算函数 (`compute_log_pref_prob_customized`)，支持 Disco-DPO 并处理数值稳定性。
    *   **指标监控扩展**: 增加了对动态 `beta`、`delta` 等新指标的跟踪与记录。

*   **其他改动**: 
    *   `.gitignore` 文件增加了新的忽略项（如 `results/`, `experiments/`）。
    *   新增了 `PLANNING.md` 文件。
    *   新增了一个用途不明的空文件 `=4.45.0`。

**总结**: 本分支的核心技术改动在于探索通过模型自身状态动态调整 DPO 关键超参数（特别是 `beta`），旨在提升偏好对齐性能或实现更复杂的算法变种。

**重要提示**: 上述列表是手动维护的总结。要获取**最完整、最精确**的代码行级差异，请务必在你的本地仓库中执行以下命令：

```bash
git fetch upstream # 确保获取了上游最新代码
git diff upstream/main...HEAD # 查看本分支相对于上游 main 分支的所有改动
```

这能让你清晰地看到每一个具体的代码变更。
