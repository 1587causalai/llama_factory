# 我的定制化对齐算法开发需求 (V1.1 - 与 V7.1 设计对齐)

## 1. 背景与目标

经过之前在 `xdpo` 目录下的一些探索，我感觉那些实现有些复杂，缺乏清晰的逻辑和职责分离。现在，我希望**从零开始，以一种更清晰、更逻辑化、更简单的方式，在 LLaMA Factory 框架内构建我设想的定制化偏好对齐算法**。核心是实现我对 Disco 和 LeDPO 背后逻辑的理解，并确保这次的设计是模块化、灵活且易于测试的。

我们已经通过详细讨论，共同设计出了一个 V7.1 版本的参数方案，记录在 `docs/parameter_design.md` 中，这份文档是后续开发的技术蓝图。而本文档，则是从我的视角出发，阐述这个蓝图背后的核心需求和设计理念。

## 2. 核心需求与设计理念

我关注的不仅仅是实现两个算法，更是要体现它们背后的核心思想：

**核心理念一：概率化奖励 (Disco 逻辑) - 用分布捕捉不确定性**

*   **我的看法**: 奖励不总是非黑即白，将其视为随机变量（如高斯分布 \(N(\mu, \sigma^2)\)）更合理。这要求我们的模型能输出这种分布。
*   **实现思路**: 需要在负责输出奖励的模型（RM阶段的 \(\pi_{\text{RM}}\) 或 DPO阶段的 \(\pi_{\theta}\)）上加一个 **Disco Head** 来预测分布参数。相应的，损失函数也得换成能比较分布的（如基于 erf/NDTR）。简单说，就是 **架构 (Head) + 算法 (Loss) 都要适配**。

**核心理念二：自适应权衡 (LeDPO / 动态 Beta 逻辑) - 让模型自己决定探索度**

*   **我的看法**: 算法中的 \(\beta\) 参数（或类似权衡系数）不该是死的。模型应该自己判断当前上下文熟不熟，然后决定是多听"老经验"（参考策略 \(\pi_{\text{ref}}\)) 的，还是多学"新东西"（偏好信号）。
*   **实现思路**: 这个判断的"责任"应该在**参考模型 \(\pi_{\text{ref}}\)**。所以，我们在 \(\pi_{\text{ref}}\) 上加一个 **Beta Head**。这个 Head 不直接定 \(\beta\)，而是输出一个调节因子 \(s(x)\)（表示相对调整量）。最终的有效 \(\beta_{\text{eff}}(x)\) 是用一个**全局基准 `beta`** 乘以这个因子 \(s(x)\) 得来的。这样设计逻辑最顺，也方便做实验看效果。

**核心设计哲学：解耦！解耦！解耦！(架构与使用的分离)**

*   **我的坚持**: 这次必须把事情分清楚。**模型有没有某个 Head (架构问题)** 和 **算法跑起来时用不用这个 Head 的输出 (算法逻辑问题)**，必须是两回事，可以分开控制。我可能需要训练一个带 Beta Head 的模型，但跑 DPO 时暂时关掉它的动态调节功能，只用固定 `beta` 来做对比。
*   **如何实现**: 通过独立的参数来分别控制。（细节见 `docs/parameter_design.md`）

## 3. 总体要求

最终，我需要的是一个**遵循 V7.1 参数设计**的、**代码实现清晰**、**模块化**的偏好对齐功能。它应该能让我灵活地组合和测试 Disco 逻辑与动态 Beta 逻辑，并且其实现方式要能清晰地反映出上述的核心理念和设计哲学，避免之前那种"历史负担"的感觉。

具体的参数细节和技术规格，请参考 `docs/parameter_design.md`。 