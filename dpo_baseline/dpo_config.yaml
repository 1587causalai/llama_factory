model_name_or_path: ~/models/Qwen1.5-0.5B
template: default

dataset:
  type: json
  file_path: dpo_baseline/data/dpo_sample.json
  format: 
    prompt: prompt
    chosen: chosen
    rejected: rejected

do_train: true
output_dir: dpo_baseline/output

# 训练超参数
overwrite_output_dir: true
num_train_epochs: 3
per_device_train_batch_size: 4
gradient_accumulation_steps: 2
learning_rate: 5.0e-5
lr_scheduler_type: cosine
warmup_ratio: 0.1
logging_steps: 10
save_steps: 100
save_total_limit: 2

# DPO特定参数
stage: dpo
pref_loss: dpo
pref_beta: 0.1
use_ref_model: true
max_prompt_length: 512
max_length: 1024 